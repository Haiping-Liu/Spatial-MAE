# Anti-overfitting configuration for limited data

model:
  vocab_size: 60000
  n_genes: 300
  d_model: 96        # 更小的模型
  d_decoder: 32      # 更小的解码器
  n_encoder_layers: 2  # 只用2层
  n_decoder_layers: 1  # 1层解码器
  n_heads: 3         # 2个头
  dropout: 0.1       
  mask_ratio: 0.3   # 大幅降低mask比例
  max_value: 512
  padding_idx: 0

dataset:
  data_dir: "/leonardo_work/EUHPC_B25_011/ST/DLPFC"
  n_spots: 512
  n_hvg: 300         
  use_hvg: true
  sampling_method: "nearest"  # 随机采样增加多样性
  normalize_total: 10000.0
  log1p: true
  max_gene_len: 300 
  patches_per_slide: 50  
  batch_size: 4
  num_workers: 4

tokenizer:
  vocab_file: null
  default_vocab_type: "census"
  special_tokens: ["<pad>", "<unk>", "<mask>", "<cls>", "<eos>"]
  default_token: "<pad>"

training:
  learning_rate: 0.0005  
  weight_decay: 0.01     
  warmup_steps: 100      
  max_epochs: 100
  gradient_clip_val: 1.0  # 放松梯度裁剪
  accumulate_grad_batches: 1
  
  optimizer: "adamw"
  adam_beta1: 0.9
  adam_beta2: 0.999    # 更稳定的beta2
  adam_eps: 1.0e-8
  
  scheduler: "cosine"
  min_lr: 1.0e-6
  t_max: 500
  
  early_stopping: true
  patience: 20  # 更多耐心
  min_delta: 0.0001  # 更小的阈值
  
  loss_type: "mse"

logging:
  project_name: "spatial-mae"
  run_name: "extreme_regularization"
  logger: "wandb"
  log_dir: "./logs"
  save_dir: "./checkpoints"
  log_every_n_steps: 10
  val_check_interval: 0.5
  save_top_k: 3
  monitor_metric: "train_loss"
  monitor_mode: "min"

compute:
  accelerator: "gpu"
  devices: 1
  precision: "32"  
  strategy: "auto"
  gradient_checkpointing: false
  compile_model: false
  detect_anomaly: false
  enable_cpu_offload: false
  empty_cache_freq: 100

seed: 42
debug: false
resume_from_checkpoint: null
test_only: false